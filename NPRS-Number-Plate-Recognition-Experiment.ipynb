{"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9061659,"sourceType":"datasetVersion","datasetId":284096}],"dockerImageVersionId":28755,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-30T02:56:20.365583Z","iopub.execute_input":"2024-07-30T02:56:20.365935Z","iopub.status.idle":"2024-07-30T02:56:20.671882Z","shell.execute_reply.started":"2024-07-30T02:56:20.365880Z","shell.execute_reply":"2024-07-30T02:56:20.670763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is 0 csv file in the current version of the dataset:\n","metadata":{}},{"cell_type":"code","source":"from scipy.io import loadmat \nimport pandas as pd\ndata = loadmat(r\"/kaggle/input/AlphaNumaric.mat\")\n# data  = {k:v for k, v in data.items() if k[0] != '_'}\n# df = pd.DataFrame({k: pd.Series(v[0]) for k, v in data.items()})  \n# df.to_csv(\"example.csv\")","metadata":{"collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-30T02:57:54.181630Z","iopub.execute_input":"2024-07-30T02:57:54.182087Z","iopub.status.idle":"2024-07-30T02:57:54.200965Z","shell.execute_reply.started":"2024-07-30T02:57:54.182010Z","shell.execute_reply":"2024-07-30T02:57:54.199995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","metadata":{}},{"cell_type":"code","source":"data  = {k:v for k, v in data.items() if k[0] != '_'}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-30T02:57:56.815701Z","iopub.execute_input":"2024-07-30T02:57:56.816055Z","iopub.status.idle":"2024-07-30T02:57:56.821408Z","shell.execute_reply.started":"2024-07-30T02:57:56.816003Z","shell.execute_reply":"2024-07-30T02:57:56.820279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y = pd.DataFrame(data['y']).T\ndf_X = pd.DataFrame(data['X']).T","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-30T02:57:59.120652Z","iopub.execute_input":"2024-07-30T02:57:59.121028Z","iopub.status.idle":"2024-07-30T02:57:59.129178Z","shell.execute_reply.started":"2024-07-30T02:57:59.120974Z","shell.execute_reply":"2024-07-30T02:57:59.127887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"letters = [chr(i) for i in range(ord('0'), ord('9')+1)] + [chr(i) for i in range(ord('a'), ord('z')+1)]\nletters = letters[:36]  # Ensure it matches the number of classes\n\n# Generate column names for X based on letter labels\nfeature_names = []\nfor letter in letters:\n    feature_names.extend([f'{letter}_Feature_{i+1}' for i in range(100)])\n\n# Ensure we have the correct number of feature names\nif len(feature_names) != df_X.shape[1]:\n    raise ValueError(\"Feature names length does not match the number of columns in X_transposed.\")\n\n# Set column names for X\ndf_X.columns = feature_names\n\nclass_column_names = []\nfor letter in letters:\n    class_column_names.extend([f'{letter}_class_{i+1}' for i in range(100)])\n\n# Ensure we have the correct number of class names\nif len(class_column_names) != df_y.shape[1]:\n    raise ValueError(\"Class names length does not match the number of columns in df_y.\")\n\n# Set column names for y\ndf_y.columns = class_column_names","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-30T02:58:08.584040Z","iopub.execute_input":"2024-07-30T02:58:08.584432Z","iopub.status.idle":"2024-07-30T02:58:08.602890Z","shell.execute_reply.started":"2024-07-30T02:58:08.584344Z","shell.execute_reply":"2024-07-30T02:58:08.601805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oh, no! There are no automatic insights available for the file types used in this dataset. As your Kaggle kerneler bot, I'll keep working to fine-tune my hyper-parameters. In the meantime, please feel free to try a different dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:58:22.809999Z","iopub.execute_input":"2024-07-30T02:58:22.810608Z","iopub.status.idle":"2024-07-30T02:58:26.259447Z","shell.execute_reply.started":"2024-07-30T02:58:22.810310Z","shell.execute_reply":"2024-07-30T02:58:26.258254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X:\", df_X.shape)\nprint(\"Shape of y:\", df_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:58:33.386222Z","iopub.execute_input":"2024-07-30T02:58:33.386653Z","iopub.status.idle":"2024-07-30T02:58:33.393500Z","shell.execute_reply.started":"2024-07-30T02:58:33.386595Z","shell.execute_reply":"2024-07-30T02:58:33.392275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transpose the DataFrames to match the correct shapes\ndf_X = df_X.T\ndf_y = df_y.T\n\n# Verify the new shapes\nprint(\"Corrected Shape of X:\", df_X.shape)  # Should be (3600, 400)\nprint(\"Corrected Shape of y:\", df_y.shape)  # Should be (3600, 36)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:58:42.829497Z","iopub.execute_input":"2024-07-30T02:58:42.829878Z","iopub.status.idle":"2024-07-30T02:58:42.838679Z","shell.execute_reply.started":"2024-07-30T02:58:42.829823Z","shell.execute_reply":"2024-07-30T02:58:42.837314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert DataFrames to numpy arrays\nX_values = df_X.values\ny_values = df_y.values\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:58:52.604031Z","iopub.execute_input":"2024-07-30T02:58:52.604445Z","iopub.status.idle":"2024-07-30T02:58:52.609390Z","shell.execute_reply.started":"2024-07-30T02:58:52.604374Z","shell.execute_reply":"2024-07-30T02:58:52.608314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_values is in one-hot encoded format already\n# If not, you should convert it to one-hot encoded format using to_categorical()\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size=0.2, random_state=42)\n\n# Normalize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:59:03.105658Z","iopub.execute_input":"2024-07-30T02:59:03.106114Z","iopub.status.idle":"2024-07-30T02:59:03.179733Z","shell.execute_reply.started":"2024-07-30T02:59:03.106025Z","shell.execute_reply":"2024-07-30T02:59:03.178813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n# Define the model\nmodel = Sequential([\n    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(36, activation='softmax')  # 36 classes\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(X_train, y_train,\n                    epochs=20,  # Adjust number of epochs as needed\n                    batch_size=32,\n                    validation_split=0.2,\n                    verbose=1)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\nprint(f'Test accuracy: {test_acc:.4f}')\n\n# Optionally, save the model\nmodel.save('letter_recognition_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:59:16.071421Z","iopub.execute_input":"2024-07-30T02:59:16.071800Z","iopub.status.idle":"2024-07-30T02:59:24.546684Z","shell.execute_reply.started":"2024-07-30T02:59:16.071744Z","shell.execute_reply":"2024-07-30T02:59:24.545537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\n\n\n# Parameters\nimg_size = (20, 20)  # Assuming each image is 20x20 pixels\nnum_classes = 36\n\n# Create directories to save images\nos.makedirs('images', exist_ok=True)\nos.makedirs('labels', exist_ok=True)\n\n# Convert each row in X to an image and save\nfor i in range(X_values.shape[0]):\n    img_array = X_values[i].reshape(img_size[0], img_size[1])  # Reshape to 2D\n    img = Image.fromarray(np.uint8(img_array * 255))  # Convert to image, scaling feature values to 0-255\n    img.save(f'images/image_{i}.png')\n\n# Save labels to a file\nnp.save('labels.npy', y_values)  # Save labels as numpy array for later use\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T02:59:44.070076Z","iopub.execute_input":"2024-07-30T02:59:44.070494Z","iopub.status.idle":"2024-07-30T02:59:45.072125Z","shell.execute_reply.started":"2024-07-30T02:59:44.070428Z","shell.execute_reply":"2024-07-30T02:59:45.071061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Path to the dataset folder\ndataset_path = '/kaggle/working/images/'\n\n# List files in the dataset directory\nfiles = os.listdir(dataset_path)\n\n# Select a few images to display\nnum_images_to_display = 169\nplt.figure(figsize=(14, 14))\n\n# Set number of rows and columns for the grid\nrows = 13\ncols = 13\n\nfor i in range(min(num_images_to_display, len(files))):\n    img_path = os.path.join(dataset_path, files[i])\n    img = Image.open(img_path)\n    img = img.transpose(Image.FLIP_LEFT_RIGHT) # Mirror the image horizontally\n    img = img.rotate(90, expand=True)\n    \n    plt.subplot(rows, cols, i + 1)\n    plt.imshow(img)\n    plt.title(f\"Image {i+1}\", fontsize=10)  # Smaller font size for titles\n    plt.axis('off')  # Hide axes\n\nplt.tight_layout(pad=0.2)  # Adjust subplots to fit into the figure area with some padding\n\n# Save the figure as a PNG file\noutput_file_path = '/kaggle/working/collage.png'\nplt.savefig(output_file_path, format='png')\n\n# Show the figure\nplt.show()\n\nprint(f\"Collage saved as {output_file_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T03:00:24.728347Z","iopub.execute_input":"2024-07-30T03:00:24.728755Z","iopub.status.idle":"2024-07-30T03:00:38.000901Z","shell.execute_reply.started":"2024-07-30T03:00:24.728687Z","shell.execute_reply":"2024-07-30T03:00:37.999809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# List files in the working directory\nprint(os.listdir('/kaggle/working'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nThis concludes your starter analysis! To go forward from here, click the blue \"Fork Notebook\" button at the top of this kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!","metadata":{}}]}